Go で 配信データリアルタイム更新
第一回サイバーエージェント合同Go言語勉強会

00:00 29 June 2016
Tags: Go, Kafka, CA-Reward, Cyberagent

Jun Tsuji
CA Reward serverside engineer
tsuji_jun@cyberagent.co.jp
http://junchang1031.hatenablog.com

* 配信データとは

* 配信データとは

広告掲載面に表示される情報。json/xml形式にて返却。
TODO: 面のイメージ
TODO: レスポンスjson

* 配信データの特徴

- MySQLの1テーブルで管理。
- 10個のマスタテーブルを元に作られる。
- 掲載面情報 x 広告情報で作成。CAリワード全体でおよそ500万件
- 更新頻度は100万/日。高負荷には1万/秒くらいになることも。
- Master/SlaveによるReadの分散をしている。
- シャーディングなどWriteの分散はしていない。

* 旧来の配信データ更新処理

* 旧来の配信データ更新処理

15分に一回、PHPのバッチが処理。
10個のマスタテーブルの更新日時を取得し、変更があったレコードを抽出して
関連する配信データを一括で更新。
処理を高速化するためPHPのプロセスをforkして幾つかのグループに分けて並列で実行。
TODO: 処理イメージ

* 問題点(Problem)

- 更新頻度が遅すぎる。ユーザーに最新の情報を1秒でも早く提供したい
- MasterのDBのリソースを有効に使えていない(普段はスカスカ、バッチ処理の時だけ負荷増・遅延、全体を通してのスループットが低い)
- 一つのテーブルに同時書込することによるDead Lockが稀に発生
- PHPつらい

* 新配信データ更新処理

* 新配信データ更新処理

以下を導入

- Apache Kafka
- fluentd
- Go

* Apache Kafka
TODO
軽く説明

* fluentd
TODO
軽く説明(知らない人いないと思うので飛ばす)
今回は以下2つのプラグインを利用
- fluent-plugin-mysql-replicator
- fluent-plugin-kafka

* Go
Kafka ConsmerをGoで実装。
sarama
TODO: 画像

* 流れ

- 各テーブルの更新をFluentdで数秒おきに取得
- 取得した更新情報を Apache Kafkaに Fluentdで送信
- Goで開発したkafka consumerが更新情報をメッセージとして取得。関連する配信情報を更新
TODO: 画像

* 解決(Solution)

  更新頻度が遅すぎる。ユーザーに最新の情報を1秒でも早く提供したい

=> `数秒程度のラグで情報を最新化できるように。`

  MasterのDBのリソースを有効に使えていない(普段はスカスカ、バッチ処理の時だけ負荷増、全体を通してのスループットが低い)

=> `書込みの負荷を分散。全体を通してのスループット向上。`

  一つのテーブルに同時書込することによるDead Lockが稀に発生

=> `transactionの小サイズ・短期間化により、発生しなくなった。(今のところ)`

  PHPつらい

=> `Go最高`

* まとめ・感想

* まとめ・感想

- リアルタイム作成というと大層なものに聞こえるが、世の中のOSSを組み合わせて、割と簡単に構築することができた。OSS最高です

- GoのChannelはkafkaなどのメッセージングシステムとの相性抜群。Java/ScalaのAkka Actorと読み替えるだけで特に詰まることなくConsumerの実装ができた。
- メッセージの部分以外のところもGoでは気軽に並行・並列化することによる速度の向上を図ることができる。
- なんでもかんでもChannelを使うのではなく、処理によってはSync.MutexやWaitGroupを使う方が自然に記述できる場合もある(パフォーマンスも向上するが、その目的ではあまりやり過ぎないこと)

